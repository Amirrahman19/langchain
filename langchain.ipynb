{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amir.rahman\\AppData\\Local\\anaconda3\\envs\\cordlife\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, pipeline\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging\n",
    "import fitz  \n",
    "import logging\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amir.rahman\\AppData\\Local\\anaconda3\\envs\\cordlife\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1564: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "c:\\Users\\amir.rahman\\AppData\\Local\\anaconda3\\envs\\cordlife\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "# Initialize transformers pipelines and models\n",
    "model_ckpt = \"papluca/xlm-roberta-base-language-detection\"\n",
    "guess_lang = pipeline(\"text-classification\", model=model_ckpt)\n",
    "\n",
    "model_name = 'liam168/trans-opus-mt-en-zh'\n",
    "model_translate = AutoModelWithLMHead.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "eng_to_ch = pipeline(\"translation_en_to_zh\", model=model_translate, tokenizer=tokenizer)\n",
    "\n",
    "model_name_id = 'mesolitica/t5-base-standard-bahasa-cased'\n",
    "model_translate_id = AutoModelWithLMHead.from_pretrained(model_name_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_id)\n",
    "eng_to_id = pipeline(\"translation_en_to_id\", model=model_translate_id, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amir.rahman\\AppData\\Local\\anaconda3\\envs\\cordlife\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'I like apples and oranges.'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "\n",
    "model_ch_to_en = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-zh-en\")\n",
    "ch_to_en = pipeline('translation_ch_to_en', model=model_ch_to_en, tokenizer=tokenizer)\n",
    "\n",
    "ch_to_en('我喜欢吃苹果和橘子')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'What are you having for dinner today?'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")\n",
    "\n",
    "model_id_to_en = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-id-en\")\n",
    "id_to_en = pipeline('translation_id_to_en', model=model_id_to_en, tokenizer=tokenizer)\n",
    "\n",
    "id_to_en('apa yang kamu makan malam hari ini?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to translate text\n",
    "def translate(sentence, lang):\n",
    "    try:\n",
    "        map = {'zh': eng_to_ch, 'id': eng_to_id}\n",
    "        f = map.get(lang, None)\n",
    "        if f is None:\n",
    "            raise ValueError(f\"Unsupported language: {lang}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        print(f\"Sentence: {sentence}, Language: {lang}\")\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saya suka mihuhuhuhuhu'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(text, target_lang):\n",
    "\n",
    "  lang = guess_lang(text)[0]['label']\n",
    "  if lang == 'zh':\n",
    "    new_text = ch_to_en(text)[0][\"translation_text\"]\n",
    "  elif lang == 'id':\n",
    "    new_text =  id_to_en(text)[0][\"translation_text\"]\n",
    "  elif lang == 'en':\n",
    "    new_text = text\n",
    "\n",
    "  print(new_text)\n",
    "\n",
    "  if target_lang == 'zh':\n",
    "    output = eng_to_ch(new_text)\n",
    "  elif target_lang == 'id':\n",
    "    output = eng_to_id(new_text)\n",
    "  else:\n",
    "    return new_text\n",
    "\n",
    "  return output[0]['translation_text']\n",
    "\n",
    "translate('I like to eat pancakes and butter', 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
